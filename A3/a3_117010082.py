# -*- coding: utf-8 -*-
"""A3_117010082.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1egaBsRru8vcyrsaNvJUJCL7sn3VpW-u8
"""

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt

# from google.colab import drive
# drive.mount('/content/drive')

path = os.getcwd()+'\\Carseats.csv'
#path = "/content/drive/MyDrive/Colab Notebooks/Carseats.csv"
f = open(path, encoding='utf-8')
data = pd.read_csv(f)

"""## Data Statistics"""

data

col_discrete = ['Urban','US','ShelveLoc']
col_continuous = list(set(data.columns.tolist()) - set(col_discrete))

data[col_continuous].describe()

plt.figure(2)
plt.figure(figsize=(14, 7))
for i in range(8):
  plt.subplot(241+i)
  col = col_continuous[i]
  plt.hist(data[col], edgecolor="black")
  plt.title(col)
plt.show()

plt.figure(2)
plt.figure(figsize=(12, 3))
for i in range(3):
  plt.subplot(131+i)
  col = col_discrete[i]
  plt.hist(data[col], edgecolor="black")
  plt.title(col)
plt.show()

"""## Train & Test Data Split"""

data.Urban = pd.Categorical(data.Urban).codes
data.US = pd.Categorical(data.US).codes
data.ShelveLoc = pd.Categorical(data.ShelveLoc).codes

y = data['Sales'].values
feature_list = ['CompPrice', 'Income', 'Advertising', 'Population', 'Price', 'ShelveLoc', 'Age', 'Education', 'Urban', 'US']
X = data[feature_list].values

X_train = X[:300,:]
y_train = y[:300]
X_test = X[300:,:]
y_test = y[300:]

"""## Decision Tree"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn import tree
from IPython.display import Image 
import graphviz
import pydotplus

"""### Find best max depth"""

train_mse_list, test_mse_list = [],[]

for i in range(1,20):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=i, min_samples_leaf=4)
  tree_model.fit(X_train, y_train)
  y_predict_train = tree_model.predict(X_train)
  y_predict_test = tree_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

plt.plot(range(1,20),train_mse_list, label="train")
plt.plot(range(1,20),test_mse_list, label="test")
plt.xlabel("max depth")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(1,20))
plt.title("performance w.r.t. different max depths")
plt.grid(True)

best_max_depth = test_mse_list.index(min(test_mse_list)) + 1
best_max_depth

"""### Find best least node size"""

train_mse_list, test_mse_list = [],[]

for i in range(1,20):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=best_max_depth, min_samples_leaf=i)
  tree_model.fit(X_train, y_train)
  y_predict_train = tree_model.predict(X_train)
  y_predict_test = tree_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

plt.plot(range(1,20),train_mse_list, label="train")
plt.plot(range(1,20),test_mse_list, label="test")
plt.xlabel("least node size")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(1,20))
plt.title("performance w.r.t. different least node size")
plt.grid(True)

best_least_node_size = test_mse_list.index(min(test_mse_list)) + 1
best_least_node_size

"""### Learned tree"""

tree_model = DecisionTreeRegressor(criterion='mse', max_depth=best_max_depth, min_samples_leaf=best_least_node_size)
tree_model.fit(X_train, y_train)
y_predict_train = tree_model.predict(X_train)
y_predict_test = tree_model.predict(X_test)

train_mse = round(mean_squared_error(y_train,y_predict_train),3)
test_mse = round(mean_squared_error(y_test,y_predict_test),3)
print("train mse is", train_mse)
print("test mse is", test_mse)

dot_data = tree.export_graphviz(tree_model, feature_names=feature_list, filled=True, rounded=True)
graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())

"""## Bagging of Trees"""

from sklearn.ensemble import BaggingRegressor

"""### Find best max depth"""

train_mse_list, test_mse_list = [],[]

for i in range(1,20):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=i, min_samples_leaf=best_least_node_size)
  bag_model = BaggingRegressor(base_estimator=tree_model, n_estimators=200, random_state=1)
  bag_model.fit(X_train, y_train)
  y_predict_train = bag_model.predict(X_train)
  y_predict_test = bag_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

plt.plot(range(1,20),train_mse_list, label="train")
plt.plot(range(1,20),test_mse_list, label="test")
plt.xlabel("max depth")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(1,20))
plt.title("performance w.r.t. different max depths")
plt.grid(True)

best_max_depth = test_mse_list.index(min(test_mse_list)) + 1
best_max_depth

"""### Find best number of trees"""

train_mse_list, test_mse_list = [],[]

for i in range(10,300,30):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=best_max_depth, min_samples_leaf=best_least_node_size)
  bag_model = BaggingRegressor(base_estimator=tree_model, n_estimators=i, random_state=1)
  bag_model.fit(X_train, y_train)
  y_predict_train = bag_model.predict(X_train)
  y_predict_test = bag_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

plt.plot(range(10,300,30),train_mse_list, label="train")
plt.plot(range(10,300,30),test_mse_list, label="test")
plt.xlabel("number of trees")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(10,300,30))
plt.title("performance w.r.t. different number of trees")
plt.grid(True)

best_num_trees = test_mse_list.index(min(test_mse_list))*30 + 10
best_num_trees

"""## Random Forests"""

from sklearn.ensemble import RandomForestRegressor

"""### Find best number of trees"""

train_mse_list, test_mse_list = [],[]

for i in range(10,300,30):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=best_max_depth, min_samples_leaf=best_least_node_size)
  randomforest_model = RandomForestRegressor(n_estimators=i, max_features='sqrt', max_depth=None, min_samples_split=2, bootstrap=True, n_jobs=1, random_state=1)
  randomforest_model.fit(X_train, y_train)
  y_predict_train = randomforest_model.predict(X_train)
  y_predict_test = randomforest_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

plt.plot(range(10,300,30),train_mse_list, label="train")
plt.plot(range(10,300,30),test_mse_list, label="test")
plt.xlabel("number of trees")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(10,300,30))
plt.title("performance w.r.t. different number of trees")
plt.grid(True)

best_num_trees = test_mse_list.index(min(test_mse_list))*30 + 10
best_num_trees

"""## AdaBoost"""

from sklearn.ensemble import AdaBoostRegressor

for i in range(10,300,30):
  tree_model = DecisionTreeRegressor(criterion='mse', max_depth=best_max_depth, min_samples_leaf=best_least_node_size)
  ada_model = AdaBoostRegressor(base_estimator=tree_model, n_estimators=1000, learning_rate=0.1, random_state=0)
  ada_model.fit(X_train, y_train)
  y_predict_train = ada_model.predict(X_train)
  y_predict_test = ada_model.predict(X_test)

  train_mse = round(mean_squared_error(y_train,y_predict_train),3)
  test_mse = round(mean_squared_error(y_test,y_predict_test),3)
  train_mse_list.append(train_mse)
  test_mse_list.append(test_mse)

"""plt.plot(range(10,300,30),train_mse_list, label="train")
plt.plot(range(10,300,30),test_mse_list, label="test")
plt.xlabel("number of trees")
plt.ylabel("mse")
plt.legend()
plt.xticks(range(10,300,30))
plt.title("performance w.r.t. different number of rounds")
plt.grid(True)

## Analysis & Comparision
"""

